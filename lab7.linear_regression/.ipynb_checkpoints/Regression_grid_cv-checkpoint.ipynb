{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6706f670",
   "metadata": {},
   "source": [
    "\n",
    "# ЛАБОРАТОРНА РОБОТА  \n",
    "\n",
    "## \"Лінійні та нелінійні регресійні моделі МН\"\n",
    "\n",
    "__Метою__ лабораторної роботи є набуття практичних навичок використання модулів бібліотеки `Scikit-learn` для вирішення наступних задач:\n",
    "\n",
    "- визначення суттєвих показчиків для регресійної моделі\n",
    "- пошук та настроювання гіперпараметрів лінійних та нелінійних регресійних моделей\n",
    "\n",
    "__Результатом__ виконання лабораторної роботи є серія моделей які прогнозують ціну кватрир на вторинному ринку житла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdfb6875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376, 176)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../lab6.Transformers/apartment_transformed.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d17c75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((376, 175), (376,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# відокремити ціловий показчик 'price'\n",
    "price = data.target\n",
    "\n",
    "# зилишити в 'data' тільки незалежні показчики\n",
    "data = data.drop(['target'], axis=1)\n",
    "\n",
    "data.shape, price.shape    # ((676, 301), (676,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b391a2e",
   "metadata": {},
   "source": [
    "## 1. Пошук значущих ознак"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e655c1",
   "metadata": {},
   "source": [
    "### Теоретичне введення"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe0105",
   "metadata": {},
   "source": [
    "__Значущі (суттеві) ознаки__ це дані, які мають сильну кореляцію або вплив на результат або прогноз моделі.\n",
    "\n",
    "Ці позазчики визначаються за допомогою процесу, який називається __відбором ознак__ ([Feature selection](https://en.wikipedia.org/wiki/Feature_selection)), який передбачає _оцінку_ та _ранжування важливості_ різних змінних у наборі даних. Це можна зробити за дпомогою статистичних тестів, кореляційного аналізу або алгоритмів машинного навчання.\n",
    "\n",
    "Після визначення значущих ознак їх можна використовувати для навчання моделі машинного навчання.\n",
    "\n",
    "Це може бути особливо важливим у моделях, де дані складні та містять багато змінних. Тому ідентифікація  суттєвих ознак може допомогти зменшити розмірність даних і покращити продуктивність моделі.\n",
    "\n",
    "Класи в модулі [sklearn.feature_selection](https://scikit-learn.org/stable/modules/feature_selection.html) можна використовувати для вибору функцій/зменшення розмірності на вибіркових наборах або для покращення показників точності оцінювачів, або для підвищення їх продуктивності на масивах даних з дуже великою розмірністю."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a207f",
   "metadata": {},
   "source": [
    "### Завдання\n",
    "\n",
    "Відібрати з вхідного набору `data` 7 найбільш суттєвих показчиків для регрісійної моделі машинного навчання."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da76799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# імпортувати з модуля 'feature_selection' селектор ознак 'SelectKBest' \n",
    "# та регрісійний тест 'f_regression'\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "443396fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m kbest_selector \u001b[38;5;241m=\u001b[39m SelectKBest(f_regression, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# застосувати селектор для побудови списку ознак\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m data_selected \u001b[38;5;241m=\u001b[39m \u001b[43mkbest_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "    \u001b[1;31m[... skipping similar frames: _wrap_method_output.<locals>.wrapped at line 142 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\base.py:851\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m--> 851\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:467\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"Run score function on (X, y) and get the appropriate features.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \n\u001b[0;32m    451\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 467\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    469\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params(X, y)\n\u001b[0;32m    472\u001b[0m score_func_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    552\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    555\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\utils\\validation.py:1120\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m     )\n\u001b[0;32m   1104\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1105\u001b[0m     X,\n\u001b[0;32m   1106\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1118\u001b[0m )\n\u001b[1;32m-> 1120\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\utils\\validation.py:1130\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1130\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1140\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\utils\\validation.py:919\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    914\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    915\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    916\u001b[0m         )\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 919\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    927\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myMLenvironment\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "# побудувати селектор 7 ознак на f-регресорі\n",
    "kbest_selector = SelectKBest(f_regression, k=7)\n",
    "\n",
    "# застосувати селектор для побудови списку ознак\n",
    "data_selected = kbest_selector.fit_transform(data, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74635da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# зберегти імена визначених селектором найбільш суттєвих ознак\n",
    "best_features = kbest_selector.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8761bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# побудувати датафрейм на визначених ознаках\n",
    "data = pd.DataFrame(data=..., columns=...)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c8685",
   "metadata": {},
   "source": [
    "### Висновки\n",
    "\n",
    "_описати загальну статистичну характеристику отриманого датасети та зробити висновки щодо можливості його використання для подальшого аналізу_\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce163fc",
   "metadata": {},
   "source": [
    "## 2. Множинна лінійна регресія"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4205a3",
   "metadata": {},
   "source": [
    "### Теоретичне введення"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b4dc56",
   "metadata": {},
   "source": [
    "__Множинна лінійна регресія__ — це статистичний метод, який використовується для встановлення зв’язку між _залежною_ (цільвою) змінною $\\textbf y$ та _кількома_ незалежними змінними $\\textbf [X]$.  \n",
    "\n",
    "__Метою__ множинної лінійної регресії є знаходження найкращого лінійного зв’язку між залежною змінною та незалежними змінними, який виражається у вигляді рівняння:\n",
    "$$y = b_0 + b_1 x_1 + b_2 x_2 + ... + b_n x_n$$\n",
    "\n",
    "Найкращій зв'язок забезпечується знаходженням таких коєфіцієнтів $[B]$, що додають мінімум обраній метриці (MSE, MAE, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6eda7e",
   "metadata": {},
   "source": [
    "### Завдання\n",
    "\n",
    "\n",
    "Порахувати показчики якості моделі [лінйной множинної регресії](https://uk.mcfairbanks.com/719-multiple-regression-formula) на визначениx п.1 значущих ознаках датасету застосувавши [кросс-валідацію з __10__ сплітами](https://scikit-learn.org/stable/modules/cross_validation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff83f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# імпортувати та побудувати лінійний регресор з параметрами за замовчанням\n",
    "from sklearn.linear_model import ...\n",
    "lr = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# імпортувати крос-валідатор 'cross_validate' з модуля 'model_selection'\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отримати результати крос-валідації по параметрам 'neg_mean_absolute_percentage_error' \n",
    "# та 'r2' на 10 сплітах передбачивши розрахунок на навчальному наборі 'return_train_score'\n",
    "cv_results_mul = cross_validate(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b944d08",
   "metadata": {},
   "source": [
    "#### занести результати в датафрейм 'cv_results_mul ' наступного вигляду:\n",
    "\n",
    "------------\n",
    "\n",
    "|помилка тесту в %   |коєф. R2 тесту  | помилка навчання в %  | коєф. R2 навчання  |\n",
    "| :------------:|:------------:|:------------:|:------------:|\n",
    "|  xx.xx | xx.xx  | xx.xx  | xx.xx  |\n",
    "|  xx.xx | xx.xx  | xx.xx  | xx.xx  |\n",
    "|  ... | ...  | ...  | ...  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ec7b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_results_mul = ...\n",
    "cv_results_mul.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de859c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# продовжити наступні команди виводу:\n",
    "print (\"середня помилка навчання = \" ...)\n",
    "print (\"середня помилка тесту = \" ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63800fff",
   "metadata": {},
   "source": [
    "### Висновки\n",
    "\n",
    "_зпираючись на отримані метрики якості зробити висновок про придатність моделі, недонавчана чи перенавчана вона і т.п._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b034005f",
   "metadata": {},
   "source": [
    "## 3. Гребнева (Ridge) регресія"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d4b9b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Теоретичне введення"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efada9e6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Гребнева регресія__ — це техніка регулярізації, яка використовується в машинному навчанні для запобігання перенавчанню лінійних регресійних моделей за рахунок додавання штрафу до функції втрат регресійної моделі, яка зменшує величину коефіцієнтів до нуля.\n",
    "\n",
    "$$\\min_w\\sum_{i=1}^n(y_i - x_i^w)^2 + \\lambda|w|_2^2$$\n",
    "\n",
    "Розмір штрафу визначається [нормою L2](https://craftappmobile.com/l1-vs-l2-regularization/) вектора коефіцієнтів, помноженою на гіперпараметр $\\large \\lambda$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e5d1a",
   "metadata": {},
   "source": [
    "### Завдання\n",
    "\n",
    "Побудувати модель на основі `ridge-регресії` та за допомогою [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) знайти таке значення _L2-регулярізатора_, яке буде\n",
    "мінізувати обрані метрики якості моделі.\n",
    "Для побудови моделі скоистатися датасетом, що отримано в  __завданні 1__ лабораторної роботи\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# імпортувати ridge-регресор з модуля `sklearn.linear_model`\n",
    "...\n",
    "\n",
    "# побудувати регресор\n",
    "ridge = Ridge(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# імпортувати сітку пошуку `GridSearchCV` з модулю sklearn.model_selection\n",
    "...\n",
    "\n",
    "# визначити параметр равномірного пошуку 100 значень параметеру `alpha` в диапазоні 0-100000 \n",
    "grid_params = { ... }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b3635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# побудувати та натренувати гребневу регресійну модель на сітці 'grid_params'\n",
    "# в якості критерія оцінки якості взяти метрику `neg_mean_absolute_percentage_error`\n",
    "\n",
    "# створюємо сітку пошуку та тренуємо на ній модель\n",
    "grid_search_model = ...\n",
    "\n",
    "grid_search_model.fit(data, price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06ea03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вивести найкращій естіматор (best_estimator_), та найкраще значення обраної метрики (best_score_)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6b8083",
   "metadata": {},
   "source": [
    "### Висновки\n",
    "\n",
    "_cпираючись на отримані метрики якості зробити висновок про придатність моделі, недонавчана чи перенавчана вона і т.п._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2792628",
   "metadata": {},
   "source": [
    "## 3. Поліноміальна регресія"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075bd403",
   "metadata": {},
   "source": [
    "### Теоретичне введення"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512d140f",
   "metadata": {},
   "source": [
    "__Поліноміальна регресія__ — це тип нелінійної регресії, у якому зв’язок між незалежною змінною $\\large x$ і залежною змінною $\\large y$ моделюється як поліноміальна функція n-го ступеня:\n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\cdots + \\beta_n x^n + \\varepsilon $$\n",
    "\n",
    "__Метою__ поліноміальної регресії є знаходження значень коефіцієнтів $ β_i$, які найкраще відповідають даним."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17ee202",
   "metadata": {},
   "source": [
    "### Завдання\n",
    "\n",
    "\n",
    "Порахувати показчики якості моделі на [поліноміальній регресії](https://uk.wikipedia.org/wiki/Поліноміальна_регресія) на визначених в п.1 значущих ознаках датасету, попередньо розширивши датасет за допомогою трансформера [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b613c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# імпортувати модуль preprocessing.PolynomialFeatures\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# побудувати трансформер ступеня 2 для побудови додаткових ознак в датасеті\n",
    "poly = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435dd363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# визначити імена відібраних показчиків\n",
    "poly_features_names = poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# побудувати датасет на визначеному поліномі `poly`\n",
    "data_poly = ...\n",
    "data_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отримати результати крос-валідації на множинном регресорі `lr` по параметрам 'neg_mean_absolute_percentage_error' \n",
    "# та 'r2' на 10 сплітах передбачивши розрахунок на навчальному наборі 'return_train_score'\n",
    "cv_results_poly = cross_validate(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02761153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# занести результати крос-валідації: помилка тесту, помилка навчання та відповідні коефіцієнти \n",
    "# детермінаційї в датафрейм `cv_results_poly`. \n",
    "cv_results_poly = ...\n",
    "\n",
    "cv_results_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# за допомогою крос-валідатора 'cross_val_predict' побудувати прогноз 'price_pred' \n",
    "# на лінійному регресорі на 10 сплітах\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "price_pred = cross_val_predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4e7e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# вивести порівняльну таблицю з двох колонок: ціна реальна, ціна прогнозна\n",
    "pred = pd.DataFrame({'ціна реальна': ...,\n",
    "                     'ціна прогнозна': ...})\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da2c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# натренувати регресор `lr` на поліноміальних ознаках `data_poly`\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сформувати таблицю коєфіцієнтів поліному\n",
    "coef = pd.DataFrame({'Ознаки': poly_features_names,\n",
    "                     'коеф.регресора': lr.coef_.astype('int')})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815a5d54",
   "metadata": {},
   "source": [
    "### Висновки\n",
    "\n",
    "_Базуючись на значенях метрик абсолютної помилки та r2-оцінки, сформулювати вашу думку чи відповідає поліноміальна модель вимогам якості та дати характеристику декільком коефіцієнтам (3-4) на свій вибір._ \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f6d1f5",
   "metadata": {},
   "source": [
    "## 5. Зберігання побудованх моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbe7ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# зберегти лінийну, гребневу та поліноміальну моделі у відпрвідних pickle-файлах:\n",
    "# 'lin_model.pkl', 'ridge_model.pkl', 'poly_model.pkl'\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
